{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3629c837-e456-4d00-bf35-05c7f03141d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing city: Bangalore\n",
      "  Reading data for region: btm,-bangalore-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Bangalore/btm,-bangalore-air-quality.csv\n",
      "  Reading data for region: hebbal,-bengaluru-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Bangalore/hebbal,-bengaluru-air-quality.csv\n",
      "  Reading data for region: peenya,-bangalore-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Bangalore/peenya,-bangalore-air-quality.csv\n",
      "\n",
      "Processing city: Thiruvananthapuram\n",
      "  Reading data for region: plammoodu,-thiruvananthapuram-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Thiruvananthapuram/plammoodu,-thiruvananthapuram-air-quality.csv\n",
      "  Reading data for region: kariavattom,-thiruvananthapuram-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Thiruvananthapuram/kariavattom,-thiruvananthapuram-air-quality.csv\n",
      "\n",
      "Processing city: Delhi\n",
      "  Reading data for region: r.k.-puram, delhi-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Delhi/r.k.-puram, delhi-air-quality.csv\n",
      "  Reading data for region: alipur,-delhi-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Delhi/alipur,-delhi-air-quality.csv\n",
      "  Reading data for region: pusa,-delhi-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Delhi/pusa,-delhi-air-quality.csv\n",
      "\n",
      "Processing city: Hyderabad\n",
      "  Reading data for region: zoo-park, bahadurpura west, hyderabad-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Hyderabad/zoo-park, bahadurpura west, hyderabad-air-quality.csv\n",
      "  Reading data for region: icrisat-patancheru, hyderabad-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Hyderabad/icrisat-patancheru, hyderabad-air-quality.csv\n",
      "  Reading data for region: ida-pashamylaram, hyderabad-air-quality.csv\n",
      "    Saved processed file to ./ProcessedData/Hyderabad/ida-pashamylaram, hyderabad-air-quality.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate AQI for a single pollutant\n",
    "def calculate_aqi(concentration, pollutant):\n",
    "    if pd.isna(concentration):  # Skip if NaN\n",
    "        return None\n",
    "    for C_lo, C_hi, I_lo, I_hi in breakpoints.get(pollutant, []):\n",
    "        if C_lo <= concentration <= C_hi:\n",
    "            return int(((I_hi - I_lo) / (C_hi - C_lo)) * (concentration - C_lo) + I_lo)  # Convert to int\n",
    "    return None\n",
    "\n",
    "# Function to calculate overall AQI for a row\n",
    "def calculate_overall_aqi(row):\n",
    "    aqi_values = []\n",
    "    for pollutant in breakpoints.keys():\n",
    "        if pollutant in row:\n",
    "            aqi = calculate_aqi(row[pollutant], pollutant)\n",
    "            if aqi is not None:\n",
    "                aqi_values.append(aqi)\n",
    "    return int(max(aqi_values)) if aqi_values else None  # Ensure result is int\n",
    "    \n",
    "# Path to the parent directory\n",
    "base_dir = \"../Datasets/\"  # Change this to your root directory\n",
    "output_dir = \"./ProcessedData/\"  # Directory to save processed files\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "# Iterate through each city\n",
    "for city in os.listdir(base_dir):\n",
    "    city_path = os.path.join(base_dir, city)\n",
    "    \n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(city_path):\n",
    "        print(f\"\\nProcessing city: {city}\")\n",
    "\n",
    "        # Create the output directory for the city\n",
    "        city_output_dir = os.path.join(output_dir, city)  # Define the output directory for the city\n",
    "        os.makedirs(city_output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "        \n",
    "        # Iterate through each region (CSV file) in the city\n",
    "        for csv_file in os.listdir(city_path):\n",
    "            csv_path = os.path.join(city_path, csv_file)\n",
    "            \n",
    "            # Check if the item is a CSV file\n",
    "            if csv_file.endswith('.csv'):\n",
    "                region_name = os.path.splitext(csv_file)[0]  # Extract region name\n",
    "                region_output_dir = os.path.join(city_output_dir, region_name)\n",
    "                os.makedirs(region_output_dir, exist_ok=True)\n",
    "\n",
    "                print(f\"  Reading data for region: {csv_file}\")\n",
    "                \n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(csv_path,encoding=\"utf-8\")\n",
    "\n",
    "                # Ensure 'Date' column is in proper datetime format\n",
    "                df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "                \n",
    "                # Sort the DataFrame by the 'Date' column\n",
    "                df = df.sort_values(by='date')\n",
    "                \n",
    "                # Reset the index after sorting\n",
    "                df = df.reset_index(drop=True)\n",
    "\n",
    "                # Remove leading/trailing spaces in column names\n",
    "                df.columns = df.columns.str.strip()\n",
    "                \n",
    "                # Remove leading/trailing spaces from all string-type columns\n",
    "                df = df.apply(lambda col: col.str.strip() if col.dtypes == 'object' else col)\n",
    "\n",
    "                # Convert numeric-looking columns to float\n",
    "                for col in df.columns:\n",
    "                    if col != 'date':  # Skip the 'date' column\n",
    "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Apply forward and backward fill (exclude the 'date' column)\n",
    "                for col in df.columns:\n",
    "                    if col != 'date':  # Skip the 'date' column\n",
    "                        df[col] = df[col].ffill()  # Forward fill\n",
    "                        df[col] = df[col].bfill() # Backward fill\n",
    "\n",
    "                # Convert all numeric columns to integers\n",
    "                for col in df.columns:\n",
    "                    if df[col].dtypes in ['float64']:  # Check for float columns\n",
    "                        df[col] = df[col].astype(int)  # Convert to int\n",
    "\n",
    "                # Define breakpoints for each pollutant\n",
    "                breakpoints = {\n",
    "                    'pm25': [\n",
    "                        (0, 12, 0, 50),\n",
    "                        (12.1, 35.4, 51, 100),\n",
    "                        (35.5, 55.4, 101, 150),\n",
    "                        (55.5, 150.4, 151, 200),\n",
    "                        (150.5, 250.4, 201, 300),\n",
    "                        (250.5, 350.4, 301, 400),\n",
    "                        (350.5, 500.4, 401, 500),\n",
    "                    ],\n",
    "                    'pm10': [\n",
    "                        (0, 54, 0, 50),\n",
    "                        (55, 154, 51, 100),\n",
    "                        (155, 254, 101, 150),\n",
    "                        (255, 354, 151, 200),\n",
    "                        (355, 424, 201, 300),\n",
    "                        (425, 504, 301, 400),\n",
    "                        (505, 604, 401, 500),\n",
    "                    ],\n",
    "                    'no2': [\n",
    "                        (0, 53, 0, 50),\n",
    "                        (54, 100, 51, 100),\n",
    "                        (101, 360, 101, 150),\n",
    "                        (361, 649, 151, 200),\n",
    "                        (650, 1249, 201, 300),\n",
    "                        (1250, 1649, 301, 400),\n",
    "                        (1650, 2049, 401, 500),\n",
    "                    ],\n",
    "                    'so2': [\n",
    "                        (0, 35, 0, 50),\n",
    "                        (36, 75, 51, 100),\n",
    "                        (76, 185, 101, 150),\n",
    "                        (186, 304, 151, 200),\n",
    "                        (305, 604, 201, 300),\n",
    "                        (605, 804, 301, 400),\n",
    "                        (805, 1004, 401, 500),\n",
    "                    ],\n",
    "                    'o3': [\n",
    "                        (0, 54, 0, 50),\n",
    "                        (55, 70, 51, 100),\n",
    "                        (71, 85, 101, 150),\n",
    "                        (86, 105, 151, 200),\n",
    "                        (106, 200, 201, 300),\n",
    "                        (201, 300, 301, 400),\n",
    "                        (301, 400, 401, 500),\n",
    "                    ],\n",
    "                }\n",
    "                # Add AQI column\n",
    "                df['AQI'] = df.apply(calculate_overall_aqi, axis=1)\n",
    "                \n",
    "                # Save processed file for the region\n",
    "                region_output_path = os.path.join(city_output_dir, csv_file)\n",
    "                df.to_csv(region_output_path, index=False)\n",
    "                print(f\"    Saved processed file to {region_output_path}\")\n",
    "                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
